{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kAD5yJ3R2N9-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LMrFaoCH2aQL"
   },
   "outputs": [],
   "source": [
    "main_dir = \"hw4_train\"\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.Grayscale(num_output_channels=1),\n",
    "                           transforms.ToTensor()\n",
    "                                     ])\n",
    "\n",
    "train_data = ImageFolder(main_dir, transform=test_transforms)\n",
    "loader = DataLoader(train_data, batch_size=1, num_workers=4)\n",
    "mstd = next(iter(loader))\n",
    "_mean = mstd[0].mean()\n",
    "_std  =  mstd[0].std()\n",
    "\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=_mean, std=_std),\n",
    "                            transforms.RandomHorizontalFlip(0.5),\n",
    "                            transforms.RandomRotation(5),\n",
    "                            transforms.RandomAdjustSharpness(2)\n",
    "                                      ])\n",
    "\n",
    "train_data = ImageFolder(main_dir, transform=train_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0ki9WqTz5_0p"
   },
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.8\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FsxHIK0i6GMU"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = torch.utils.data.random_split(train_data,\n",
    "                                           [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "e8JRhYqS6KRj"
   },
   "outputs": [],
   "source": [
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = train_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "v77lV_Iv6Kz2"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = torch.utils.data.DataLoader(train_data,\n",
    "                                 shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE,)\n",
    "\n",
    "valid_iterator = torch.utils.data.DataLoader(valid_data,\n",
    "                                 batch_size=BATCH_SIZE,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "V0wrOnzP8E1c"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataloaders = {'train': train_iterator, 'val': valid_iterator}\n",
    "dataset_sizes= {'train': len(train_data), 'val': len(valid_data)}\n",
    "\n",
    "model = resnet18(NUM_CLASSES)\n",
    "model.to(device)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        #print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "               phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        #print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "98lw89wxWhA3",
    "outputId": "bfa9d865-bd54-475a-e79e-a7f6376bac9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5182 Acc: 0.8141\n",
      "val Loss: 0.4012 Acc: 0.8556\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# make resnet 18 model\n",
    "model_ft = models.resnet18(pretrained=False)\n",
    "\n",
    "# change input layer\n",
    "# the default number of input channel in the resnet is 3, but our images are 1 channel. So we have to change 3 to 1.\n",
    "# nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) <- default\n",
    "model_ft.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) \n",
    "\n",
    "# change fc layer\n",
    "# the number of classes in our dataset is 10. default is 1000.\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# decay LR by a factor of 0.1 every 5 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
    "\n",
    "# train model\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes,\n",
    "                       num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkLWYyvJZUJ6"
   },
   "outputs": [],
   "source": [
    "PATH = F\"ResNet.pth\"\n",
    "torch.save(model_ft.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-0kUKNuZm-Z"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import natsort\n",
    "\n",
    "def test(model, data_loader):\n",
    "    model.eval()\n",
    "\n",
    "    with open('prediction.txt', 'w') as f:\n",
    "      with torch.no_grad():\n",
    "          for data in test_loader:\n",
    "              output = F.log_softmax(model(data), dim=1)\n",
    "              _, pred = torch.max(output, dim=1)\n",
    "              for i in pred.numpy():\n",
    "                f.write(str(i))\n",
    "                f.write('\\n')\n",
    "      f.close()\n",
    "\n",
    "\n",
    "class CustomDataSet(Dataset):\n",
    "    def __init__(self, main_dir, transform):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc)\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnOjV7CHZoCA"
   },
   "outputs": [],
   "source": [
    "test_path = 'hw4_test' \n",
    "\n",
    "my_dataset = CustomDataSet(test_path, transform=test_transforms)\n",
    "test_loader = data.DataLoader(my_dataset, batch_size=50, shuffle=False, drop_last = False)\n",
    "\n",
    "PATH = \"ResNet.pth\"\n",
    "model = model_ft\n",
    "model.load_state_dict(torch.load (PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzGOti72a6Q0"
   },
   "outputs": [],
   "source": [
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet18.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
