{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet18.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "aJ4x7dCSBZ16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf6bcc76-da90-4b22-b562-837768a210c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/Colab Notebooks/hw4_train.zip'"
      ],
      "metadata": {
        "id": "z_Q4Us6MFOKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kAD5yJ3R2N9-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.models import resnet18\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsKlkU352mDk",
        "outputId": "c031a62a-0c5f-4867-fcfa-c68a1ef3de50"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd hw4_train\n",
        "!rm -r .data\n",
        "!find . -name '.DS_Store' -type f -delete\n",
        "!ls -a\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KN4w_pM72mt7",
        "outputId": "0e697dd5-4f87-4de1-9f0a-1c5e0186e0ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hw4_train\n",
            "rm: cannot remove '.data': No such file or directory\n",
            ".  ..  0  1  2\t3  4  5  6  7  8  9\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQfsaAYpGg5n",
        "outputId": "cf16bee7-e58e-4d00-d1fe-444d2f69a8e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_dir = \"/content/hw4_train\"\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize(mean=0.1793, std=0.2323)\n",
        "                                      ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.Grayscale(num_output_channels=1),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=0.1793, std=0.2323)\n",
        "                                     ])\n",
        "\n",
        "train_data = ImageFolder(main_dir, transform=train_transforms)"
      ],
      "metadata": {
        "id": "LMrFaoCH2aQL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VALID_RATIO = 0.9\n",
        "\n",
        "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "n_valid_examples = len(train_data) - n_train_examples"
      ],
      "metadata": {
        "id": "0ki9WqTz5_0p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, valid_data = torch.utils.data.random_split(train_data,\n",
        "                                           [n_train_examples, n_valid_examples])"
      ],
      "metadata": {
        "id": "FsxHIK0i6GMU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms"
      ],
      "metadata": {
        "id": "e8JRhYqS6KRj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator = torch.utils.data.DataLoader(train_data,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=BATCH_SIZE,)\n",
        "\n",
        "valid_iterator = torch.utils.data.DataLoader(valid_data,\n",
        "                                 batch_size=BATCH_SIZE,)"
      ],
      "metadata": {
        "id": "v77lV_Iv6Kz2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "# Hyperparameters\n",
        "RANDOM_SEED = 1\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Architecture\n",
        "NUM_FEATURES = 28*28\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "# Other\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "GRAYSCALE = True"
      ],
      "metadata": {
        "id": "venck23l6Xy0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################\n",
        "### MODEL\n",
        "##########################\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes, grayscale):\n",
        "        self.inplanes = 64\n",
        "        if grayscale:\n",
        "            in_dim = 1\n",
        "        else:\n",
        "            in_dim = 1\n",
        "        super(ResNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, (2. / n)**.5)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        # because MNIST is already 1x1 here:\n",
        "        # disable avg pooling\n",
        "        #x = self.avgpool(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        logits = self.fc(x)\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas\n",
        "\n",
        "\n",
        "\n",
        "def resnet18(num_classes):\n",
        "    \"\"\"Constructs a ResNet-18 model.\"\"\"\n",
        "    model = ResNet(block=BasicBlock, \n",
        "                   layers=[2, 2, 2, 2],\n",
        "                   num_classes=NUM_CLASSES,\n",
        "                   grayscale=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "f0fjw1BO76h3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZvJZofh9JmQ",
        "outputId": "d6b39807-818c-4fa2-87d2-0a9994f2efa5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "dataloaders = {'train': train_iterator, 'val': valid_iterator}\n",
        "dataset_sizes= {'train': len(train_data), 'val': len(valid_data)}\n",
        "\n",
        "model = resnet18(NUM_CLASSES)\n",
        "model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) \n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, dataloaders, dataset_sizes, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        #print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "               phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        #print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "V0wrOnzP8E1c"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "from torchvision import models\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# make resnet 18 model\n",
        "model_ft = models.resnet18(pretrained=False)\n",
        "\n",
        "# change input layer\n",
        "# the default number of input channel in the resnet is 3, but our images are 1 channel. So we have to change 3 to 1.\n",
        "# nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) <- default\n",
        "model_ft.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) \n",
        "\n",
        "# change fc layer\n",
        "# the number of classes in our dataset is 10. default is 1000.\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
        "\n",
        "# decay LR by a factor of 0.1 every 5 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=5, gamma=0.1)\n",
        "\n",
        "# train model\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, dataset_sizes,\n",
        "                       num_epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98lw89wxWhA3",
        "outputId": "bfa9d865-bd54-475a-e79e-a7f6376bac9b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5284 Acc: 0.8113\n",
            "val Loss: 0.4828 Acc: 0.8234\n",
            "train Loss: 0.3618 Acc: 0.8672\n",
            "val Loss: 0.3208 Acc: 0.8821\n",
            "train Loss: 0.3049 Acc: 0.8893\n",
            "val Loss: 0.3059 Acc: 0.8849\n",
            "train Loss: 0.2630 Acc: 0.9042\n",
            "val Loss: 0.3117 Acc: 0.8853\n",
            "train Loss: 0.2386 Acc: 0.9122\n",
            "val Loss: 0.2978 Acc: 0.8915\n",
            "train Loss: 0.1437 Acc: 0.9484\n",
            "val Loss: 0.2753 Acc: 0.9016\n",
            "train Loss: 0.1100 Acc: 0.9596\n",
            "val Loss: 0.2900 Acc: 0.9052\n",
            "train Loss: 0.0876 Acc: 0.9677\n",
            "val Loss: 0.3193 Acc: 0.9067\n",
            "train Loss: 0.0658 Acc: 0.9772\n",
            "val Loss: 0.3496 Acc: 0.9030\n",
            "train Loss: 0.0474 Acc: 0.9836\n",
            "val Loss: 0.4087 Acc: 0.8982\n",
            "Training complete in 4m 37s\n",
            "Best val Acc: 0.906746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = F\"/content/gdrive/MyDrive/Colab Notebooks/ResNet.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "JkLWYyvJZUJ6"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader \n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import natsort\n",
        "\n",
        "def test(model, data_loader):\n",
        "    model.eval()\n",
        "\n",
        "    with open('predictions.txt', 'w') as f:\n",
        "      with torch.no_grad():\n",
        "          for data in test_loader:\n",
        "              output = F.log_softmax(model(data), dim=1)\n",
        "              _, pred = torch.max(output, dim=1)\n",
        "              for i in pred.numpy():\n",
        "                f.write(str(i))\n",
        "                f.write('\\n')\n",
        "      f.close()\n",
        "\n",
        "\n",
        "class CustomDataSet(Dataset):\n",
        "    def __init__(self, main_dir, transform):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        all_imgs = os.listdir(main_dir)\n",
        "        self.total_imgs = natsort.natsorted(all_imgs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.total_imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
        "        image = Image.open(img_loc)\n",
        "        tensor_image = self.transform(image)\n",
        "        return tensor_image"
      ],
      "metadata": {
        "id": "1-0kUKNuZm-Z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "test_path = '/content/hw4_test' \n",
        "\n",
        "my_dataset = CustomDataSet(test_path, transform=test_transforms)\n",
        "test_loader = data.DataLoader(my_dataset, batch_size=50, shuffle=False, drop_last = False)\n",
        "\n",
        "PATH = \"/content/gdrive/MyDrive/Colab Notebooks/CNN.pth\"\n",
        "model = model_ft\n",
        "model.to('cpu')\n",
        "# model.load_state_dict(torch.load (PATH))"
      ],
      "metadata": {
        "id": "vnOjV7CHZoCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/hw4_test/\n",
        "!find . -name '.DS_Store' -type f -delete\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jybbuZMMbT0U",
        "outputId": "e3b807d0-e52c-490c-fdf9-230119b2fee7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hw4_test\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(model, test_loader)"
      ],
      "metadata": {
        "id": "GzGOti72a6Q0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/Colab Notebooks/hw4_test.zip'"
      ],
      "metadata": {
        "id": "uJyKgbZ8aTDt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}